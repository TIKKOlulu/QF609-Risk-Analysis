{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55027b0c-a48d-43d6-b106-efebfed718dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date as pdate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import scipy.stats as stat\n",
    "import scipy\n",
    "import math\n",
    "import statistics\n",
    "from statistics import NormalDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182e3c02-3c83-4c43-a93c-54e68f1ad0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################################################\n",
    "########### Helper function and class ###############\n",
    "#####################################################\n",
    "\n",
    "# Zero Rate Curve \n",
    "class ZeroRateCurve:\n",
    "    def __init__(self, vdate, dates, rates):\n",
    "        self.vdate = vdate    \n",
    "        self.dates = dates\n",
    "        self.rates = np.array(rates)\n",
    "        self.times = np.array([(d-vdate).days/365 for d in dates])\n",
    "        self.interp = interpolate.interp1d(self.times, self.rates, kind = 'linear', fill_value=(self.rates[0], self.rates[-1]), bounds_error=False)\n",
    "        \n",
    "    def getDF(self, d):\n",
    "        t = (d-self.vdate).days/365\n",
    "        return math.exp(-t*self.interp(t))\n",
    "\n",
    "    def getShiftedCurves(self, shiftsize):\n",
    "        curves =[]\n",
    "        l = len(self.rates)\n",
    "        for i in range(0, l):\n",
    "            shiftedRates = self.rates.copy()\n",
    "            shiftedRates[i] = shiftedRates[i] + shiftsize\n",
    "            curves = curves + [ ZeroRateCurve(self.vdate, self.dates, shiftedRates.copy()) ]\n",
    "        return curves\n",
    "        \n",
    "\n",
    "# Swap Pricing Functions\n",
    "# This is a simplified implementation where we assume:\n",
    "# (1) no business day adjustment, \n",
    "# (2) fixed leg freq = float leg freq\n",
    "# (3) payment is right on the accrual end date\n",
    "class SofrSwap:\n",
    "    def __init__(self, notional, isPay, vdate, tenor, strike, freq):\n",
    "        self.notional = notional    \n",
    "        self.payIndicator = 1.0 if isPay else -1.0\n",
    "        self.vdate = vdate    \n",
    "        self.tenor = tenor\n",
    "        self.freq = freq\n",
    "        self.strike = strike\n",
    "        self.dates = self._generateSwapDates()\n",
    "\n",
    "    # d: trade date\n",
    "    # t: tenor in number of years\n",
    "    # f: no. of payment per years\n",
    "    def _generateSwapDates(self):\n",
    "        n = 12/self.freq\n",
    "        m = self.freq * self.tenor\n",
    "        dates = [ self.vdate + relativedelta(months=n*(i+1)) for i in range(0, m) ]\n",
    "        return dates\n",
    "\n",
    "    def getSchedules(self):\n",
    "        s = []\n",
    "        ds = self.vdate\n",
    "        for d in self.dates:\n",
    "            s = s + [ (d, (d-ds).days/365 ) ]\n",
    "            ds = d\n",
    "        return s\n",
    "\n",
    "def price_swap(curve, swap):\n",
    "    schedule = swap.getSchedules()\n",
    "    fixedLegVal = 0.0\n",
    "    fltLegVal = 0.0\n",
    "    df_start = curve.getDF(swap.vdate)\n",
    "    for (d, a) in schedule:\n",
    "        df = curve.getDF(d)\n",
    "        fwd = 1.0 / a * (df_start / df - 1.0)\n",
    "        fixedLegVal = fixedLegVal + df * a * swap.strike \n",
    "        fltLegVal = fltLegVal + df * a * fwd \n",
    "        df_start = df\n",
    "    return swap.notional * swap.payIndicator * (fltLegVal - fixedLegVal)\n",
    "\n",
    "def price_swap_details(curve, swap):\n",
    "    schedule = swap.getSchedules()\n",
    "    fixedLegVal = 0.0\n",
    "    fltLegVal = 0.0\n",
    "    df_start = curve.getDF(swap.vdate)\n",
    "    details = []\n",
    "    for (d, a) in schedule:\n",
    "        df = curve.getDF(d)\n",
    "        fwd = 1.0 / a * (df_start / df - 1.0)\n",
    "        details = details + [[df_start, df, a, fwd, swap.strike]]\n",
    "        df_start = df\n",
    "    return pd.DataFrame(details, columns=['df_start', 'df_end', 'accrual', 'forward_rate', 'strike'])\n",
    "\n",
    "    \n",
    "def pv01(curve, swap, shiftsize):    \n",
    "    pv0 = price_swap(curve, swap)\n",
    "    shiftedCurves = curve.getShiftedCurves(shiftsize)\n",
    "    risks = []\n",
    "    #print(\"pv0: \" + str(pv0))\n",
    "    for c in shiftedCurves:\n",
    "        pv = price_swap(c, swap)\n",
    "        risks = risks + [pv - pv0]\n",
    "    return pd.DataFrame(risks, columns =['pv01'])\n",
    "\n",
    "# full revaluation 1d pnl evaluation\n",
    "def pnl_full(base_date, crv_dates, stock_notl, stock_returns, swap, base_swap_price, base_crv, rate_returns):\n",
    "    base_rates = base_crv.rates\n",
    "    scn_rates = [r+dr for r, dr in zip(base_rates, rate_returns)]\n",
    "    scn_crv = ZeroRateCurve(base_date, crv_dates, scn_rates)\n",
    "    scn_swap_price = price_swap(scn_crv, swap)\n",
    "    swap_pnl = scn_swap_price - base_swap_price\n",
    "    stock_pnl = stock_notl * np.sum(stock_returns)\n",
    "    return (swap_pnl+stock_pnl)\n",
    "\n",
    "# sensitivity based 1d pnl evaluation \n",
    "def pnl_sen(stock_notl, stock_returns, swap_pv01s, rate_returns):\n",
    "    stock_pnl = stock_notl * np.sum(stock_returns)\n",
    "    swap_pnl = np.inner(swap_pv01s, rate_returns)\n",
    "    return (swap_pnl+stock_pnl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e79e79-66f8-4496-a460-413a2e790d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================== PARAMETRIC VAR =======================================================\n",
      "mean: 21,305\n",
      "variance: 332,910,331,242\n",
      "Parametric VaR [1d, 95%]: 927,749\n",
      "============================================================================================================================\n",
      "\n",
      "===================================================== Monte Carlo VAR ======================================================\n",
      "Monte-Carlo-Full-Revaluation VaR [1d, 95%]: 935,547\n",
      "Monte-Carlo-Sensitivity-Based VaR [1d, 95%]: 930,265)\n",
      "============================================================================================================================\n",
      "\n",
      "===================================================== Historical VAR =======================================================\n",
      "Historical-Full-Revaluation VaR [1d, 95%]: 985,468\n",
      "Historical-Sensitivity-Based VaR [1d, 95%]: 979,371\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "############## Run VaR Calculations #################\n",
    "#####################################################\n",
    "\n",
    "file_path = \"D:/OneDrive/main/workspace/smu-teaching/SMUTeaching/2025/group-assignment/\"\n",
    "offset = 693594\n",
    "\n",
    "df_sofr = pd.read_csv(file_path + \"hist_sofr_crvs.csv\").set_index('Date')\n",
    "df_sofr.index = pd.to_datetime(df_sofr.index).date\n",
    "df_sofr = df_sofr.sort_index()\n",
    "tenors = df_sofr.columns.tolist()\n",
    "sofr_interps = []\n",
    "date_sofr = [ d.toordinal()-693594  for d in df_sofr.index.tolist()]\n",
    "for t in tenors:\n",
    "  hist_rates = df_sofr[t].tolist()\n",
    "  sofr_interps = sofr_interps + [ scipy.interpolate.interp1d(date_sofr, hist_rates)  ]\n",
    "\n",
    "df_appl = pd.read_csv(file_path + \"hist_appl.csv\").set_index('Date')\n",
    "df_appl.index = pd.to_datetime(df_appl.index).date\n",
    "df_appl = df_appl.sort_index()\n",
    "\n",
    "df_msft = pd.read_csv(file_path + \"hist_msft.csv\").set_index('Date')\n",
    "df_msft.index = pd.to_datetime(df_msft.index).date\n",
    "df_msft = df_msft.sort_index()\n",
    "\n",
    "df_ford = pd.read_csv(file_path + \"hist_ford.csv\").set_index('Date')\n",
    "df_ford.index = pd.to_datetime(df_ford.index).date\n",
    "df_ford = df_ford.sort_index()\n",
    "\n",
    "df_bac = pd.read_csv(file_path + \"hist_bac.csv\").set_index('Date')\n",
    "df_bac.index = pd.to_datetime(df_bac.index).date\n",
    "df_bac = df_bac.sort_index()\n",
    "\n",
    "d1 = [ d.toordinal()-693594  for d in df_appl.index.tolist()]\n",
    "p1 = df_appl['AdjClose'].tolist()\n",
    "interp1 =  scipy.interpolate.interp1d(d1, p1)\n",
    "\n",
    "d2 = [ d.toordinal()-693594  for d in df_msft.index.tolist()]\n",
    "p2 = df_msft['AdjClose'].tolist()\n",
    "interp2 =  scipy.interpolate.interp1d(d2, p2)\n",
    "\n",
    "d3 = [ d.toordinal()-693594  for d in df_ford.index.tolist()]\n",
    "p3 = df_ford['AdjClose'].tolist()\n",
    "interp3 =  scipy.interpolate.interp1d(d3, p3)\n",
    "\n",
    "d4 = [ d.toordinal()-693594  for d in df_bac.index.tolist()]\n",
    "p4 = df_bac['AdjClose'].tolist()\n",
    "interp4 =  scipy.interpolate.interp1d(d4, p4)\n",
    "\n",
    "dlist = sorted(list(set(d1) | set(d2) | set(d3) | set(d4) | set(date_sofr)))\n",
    "\n",
    "numchg = len(dlist)-1\n",
    "appl = [ interp1(dlist[i+1]).flat[0] / interp1(dlist[i]).flat[0] - 1.0  for i in range(numchg) ]\n",
    "msft = [ interp2(dlist[i+1]).flat[0] / interp2(dlist[i]).flat[0] - 1.0  for i in range(numchg) ]\n",
    "ford = [ interp3(dlist[i+1]).flat[0] / interp3(dlist[i]).flat[0] - 1.0  for i in range(numchg) ]\n",
    "bac = [ interp4(dlist[i+1]).flat[0] / interp4(dlist[i]).flat[0] - 1.0  for i in range(numchg) ]\n",
    "\n",
    "sofr_chg = []\n",
    "for interp in sofr_interps:\n",
    "    chg = []\n",
    "    for i in range(numchg):\n",
    "        chg = chg + [ (interp(dlist[i+1]).flat[0] - interp(dlist[i]).flat[0]) ]\n",
    "    sofr_chg = sofr_chg + [chg]\n",
    "\n",
    "df_sofr_chg = pd.DataFrame(data =  np.transpose(np.array(sofr_chg)), index = dlist[1:len(dlist)], columns = tenors) \n",
    "\n",
    "stock_chg_dict = { 'appl' : appl, 'msft' : msft, 'ford' : ford, 'bac' : bac,}\n",
    "df_stock_chg = pd.DataFrame(stock_chg_dict, index = dlist[1:len(dlist)],  columns=['appl', 'msft', 'ford', 'bac'])\n",
    "\n",
    "df_all = pd.concat([df_stock_chg, df_sofr_chg], axis=1)\n",
    "cols = df_all.columns.tolist()\n",
    "corr_mat = df_all.corr()\n",
    "cov_mat = df_all.cov()\n",
    "factor_mean = df_all.mean().to_list()\n",
    "factor_std = df_all.std().to_list()\n",
    "\n",
    "# set up base curve, i.e. the zero rate curve using the zero rates as of 2023-10-30\n",
    "baseDate = pdate(2023,10,30)\n",
    "crv_tenor_d = [1]\n",
    "crv_tenor_m = [1,2,3,6,9]\n",
    "crv_tenor_y = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,25,30,35,40]\n",
    "crv_dates = [baseDate + relativedelta(days=i) for i in crv_tenor_d]\n",
    "crv_dates = crv_dates + [ baseDate + relativedelta(months=i) for i in crv_tenor_m]\n",
    "crv_dates = crv_dates + [ baseDate + relativedelta(years=i) for i in crv_tenor_y]\n",
    "base_rates = df_sofr.loc[baseDate]\n",
    "baseCurve = ZeroRateCurve(baseDate, crv_dates, base_rates)\n",
    "\n",
    "swap = SofrSwap(100000000, True, baseDate, 10, 0.042, 1)\n",
    "stock_notl = 1000000\n",
    "\n",
    "#base_price = price_swap(baseCurve, swap)\n",
    "#print(base_price)\n",
    "#print(price_swap_details(baseCurve, swap))\n",
    "#print(swap_risks)\n",
    "\n",
    "\n",
    "# parametric VaR\n",
    "rate_shift = 0.0001\n",
    "swap_risks = pv01(baseCurve, swap, rate_shift)\n",
    "w_stock = [stock_notl, stock_notl, stock_notl, stock_notl ]\n",
    "w_sofr = [ risk/rate_shift   for risk in swap_risks['pv01'].tolist()]\n",
    "w_parametric = np.array( w_stock + w_sofr)\n",
    "\n",
    "port_m =  np.inner(w_parametric, factor_mean)\n",
    "port_v = np.inner(np.dot(w_parametric, cov_mat), w_parametric)\n",
    "param_var = np.abs(stat.norm.ppf(0.05, loc=port_m, scale=np.sqrt(port_v)))\n",
    "print(\"\")\n",
    "print(\"===================================================== PARAMETRIC VAR =======================================================\")\n",
    "print(f\"mean: {port_m:,.0f}\")\n",
    "print(f\"variance: {port_v:,.0f}\")\n",
    "print(f\"Parametric VaR [1d, 95%]: {param_var:,.0f}\")\n",
    "print(\"============================================================================================================================\")\n",
    "\n",
    "# Monte Carlo VaR\n",
    "n_mc = 100000\n",
    "dim = corr_mat.shape[0]\n",
    "factor_loadings = np.linalg.cholesky(corr_mat)\n",
    "np.random.seed(1000000)\n",
    "uniforms = np.random.uniform(size=(n_mc, dim))\n",
    "snorms = [ [NormalDist().inv_cdf(u) for u in r]  for r in uniforms]\n",
    "\n",
    "snorms_correlated = np.dot(snorms, factor_loadings.transpose())\n",
    "return1d_sample = [ np.add(factor_mean, np.multiply(factor_std, z).tolist()).tolist()  for z in snorms_correlated]\n",
    "\n",
    "mc_pnl_full=[]\n",
    "mc_pnl_sen =[]\n",
    "base_swap_price = price_swap(baseCurve, swap)\n",
    "\n",
    "for i in range(0,n_mc):\n",
    "    mc_pnl_full = mc_pnl_full + [pnl_full(baseDate, crv_dates, stock_notl, return1d_sample[i][0:4], swap, base_swap_price, baseCurve, return1d_sample[i][4:])]\n",
    "    mc_pnl_sen = mc_pnl_sen + [pnl_sen(stock_notl, return1d_sample[i][0:4], w_sofr, return1d_sample[i][4:])]\n",
    "\n",
    "mc_var_full = np.abs(np.percentile(mc_pnl_full, 5))\n",
    "mc_var_full_std = np.std(mc_pnl_full)\n",
    "mc_var_sen = np.abs(np.percentile(mc_pnl_sen, 5))\n",
    "mc_var_sen_std = np.std(mc_pnl_sen)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"===================================================== Monte Carlo VAR ======================================================\")\n",
    "print(f\"Monte-Carlo-Full-Revaluation VaR [1d, 95%]: {mc_var_full:,.0f}\")\n",
    "print(f\"Monte-Carlo-Sensitivity-Based VaR [1d, 95%]: {mc_var_sen:,.0f})\")\n",
    "print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "# Historical VaR\n",
    "hist_returns = df_all.to_numpy().tolist()\n",
    "hist_pnl_full=[]\n",
    "hist_pnl_sen =[]\n",
    "for i in range(0, len(hist_returns)):\n",
    "    hist_pnl_full = hist_pnl_full + [pnl_full(baseDate, crv_dates, stock_notl, hist_returns[i][0:4], swap, base_swap_price, baseCurve, hist_returns[i][4:])]\n",
    "    hist_pnl_sen = hist_pnl_sen + [pnl_sen(stock_notl, hist_returns[i][0:4], w_sofr, hist_returns[i][4:])]\n",
    "\n",
    "hist_var_full = np.abs(np.percentile(hist_pnl_full, 5))\n",
    "hist_var_full_std = np.std(hist_pnl_full)\n",
    "hist_var_sen = np.abs(np.percentile(hist_pnl_sen, 5))\n",
    "hist_var_sen_std = np.std(hist_pnl_sen)\n",
    "\n",
    "print(\"\")\n",
    "print(\"===================================================== Historical VAR =======================================================\")\n",
    "print(f\"Historical-Full-Revaluation VaR [1d, 95%]: {hist_var_full:,.0f}\")\n",
    "print(f\"Historical-Sensitivity-Based VaR [1d, 95%]: {hist_var_sen:,.0f}\")\n",
    "print(\"============================================================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ab3a3968-52fc-4de5-91d4-67d0b401420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
